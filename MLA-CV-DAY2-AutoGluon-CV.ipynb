{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Image Classification using AutoGluon\n",
    "\n",
    "In this tutorial, we load images and the corresponding labels into [AutoGluon](https://autogluon.mxnet.io/index.html) and use this data to obtain a neural network that can classify new images. This is different from traditional machine learning where we need to manually define the neural network and then specify the hyperparameters in the training process. Instead, with just a single call to AutoGluon’s fit function, AutoGluon automatically trains many models with different hyperparameter configurations and returns the model that achieved the highest level of accuracy.\n",
    "\n",
    "Note: Please use **GPU** for training. CPU training will lead to an unceasing running script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pathos 0.2.8 requires dill>=0.3.4, but you have dill 0.3.3 which is incompatible.\r\n",
      "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.3 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -q nvidia-ml-py3==7.352.0\n",
    "! pip install -q torch==1.10.1\n",
    "! pip install -q torchvision==0.11.2\n",
    "! pip install -q d2l==0.16.0\n",
    "! pip install -q numpy==1.19.5\n",
    "! pip install -q setuptools==54.1.1\n",
    "! pip install -q wheel==0.36.2\n",
    "! pip install -q autogluon==0.1.0\n",
    "! pip install -q timm==0.4.12\n",
    "! pip install -q gluoncv==0.10.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.vision import ImagePredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use AutoGluon for computer vision task training, we need to organize our data with the following structure:\n",
    "\n",
    "    data/\n",
    "    ├── train/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "    ├── test/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "\n",
    "Here each subfolder contains all images that belong to that category, e.g., `class1` contains all images belonging to the first class. We generally recommend at least 100 training images per class for reasonable classification performance, but this might depend on the type of images in your specific use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset\n",
    "\n",
    "For demonstration purposes, we use a subset of the __Shopee-IET__ dataset from [Kaggle](https://www.kaggle.com/competitions). Each image in this data depicts a clothing item and the corresponding label specifies its clothing category. Our subset of the data contains the following possible labels: BabyPants, BabyShirt, womencasualshoes, womenchiffontop.\n",
    "\n",
    "We download the data subset and create training/test dataset folders like below. If you use this on your own dataset, just point it to your training or test folder. Example: `train_dataset = ImagePredictor.Dataset.from_folder('mydataset/train')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.gluoncv/archive/shopee-iet.zip from https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40895/40895 [00:00<00:00, 42922.99KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n"
     ]
    }
   ],
   "source": [
    "path = 'https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip'\n",
    "train_dataset, _, test_dataset = ImagePredictor.Dataset.from_folders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 image  label\n",
      "0    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "1    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "2    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "3    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "4    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "..                                                 ...    ...\n",
      "795  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "796  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "797  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "798  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "799  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "\n",
      "[800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AutoGluon to Fit Models\n",
    "\n",
    "Now, let's fit a __classifier__ using AutoGluon [predictor.fit()](https://auto.gluon.ai/stable/tutorials/image_prediction/beginner.html). Within fit, the dataset is __automatically__ split into training and validation sets. The model with the best hyperparameter configuration is selected based on its performance on the __validation set__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluoncv.auto.tasks.image_classification:Randomly split train_data into train[717]/validation[83] splits.\n",
      "INFO:gluoncv.auto.tasks.image_classification:Starting fit without HPO\n",
      "INFO:ImageClassificationEstimator:modified configs(<old> != <new>): {\n",
      "INFO:ImageClassificationEstimator:root.train.batch_size 128 != 16\n",
      "INFO:ImageClassificationEstimator:root.train.lr        0.1 != 0.01\n",
      "INFO:ImageClassificationEstimator:root.train.epochs    10 != 15\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.num_training_samples 1281167 != -1\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "INFO:ImageClassificationEstimator:root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "INFO:ImageClassificationEstimator:root.valid.batch_size 128 != 16\n",
      "INFO:ImageClassificationEstimator:root.img_cls.model   resnet50_v1 != resnet50_v1b\n",
      "INFO:ImageClassificationEstimator:}\n",
      "INFO:ImageClassificationEstimator:Saved config to /home/ec2-user/SageMaker/notebooks/day_2/e6a25eae/.trial_0/config.yaml\n",
      "INFO:root:Model file not found. Downloading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55344/55344 [00:00<00:00, 68016.02KB/s]\n",
      "INFO:ImageClassificationEstimator:Start training from [Epoch 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-19 06:51:41.116 ip-172-16-58-12:13573 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None[2022-10-19 06:51:41.116 ip-172-16-58-12:13591 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None[2022-10-19 06:51:41.116 ip-172-16-58-12:13600 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None[2022-10-19 06:51:41.117 ip-172-16-58-12:13582 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\n",
      "\n",
      "\n",
      "[2022-10-19 06:51:41.248 ip-172-16-58-12:13591 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.[2022-10-19 06:51:41.248 ip-172-16-58-12:13582 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.[2022-10-19 06:51:41.248 ip-172-16-58-12:13573 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.[2022-10-19 06:51:41.248 ip-172-16-58-12:13600 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    }
   ],
   "source": [
    "predictor = ImagePredictor()\n",
    "\n",
    "time_limit = 10 * 60 # how long fit() should run (in seconds)\n",
    "predictor.fit(train_dataset,\n",
    "              epochs=10,\n",
    "              time_limit=time_limit,\n",
    "              ngpus_per_trial=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results\n",
    "\n",
    "Autogluon also provides the training results, which can be accessed by calling `predictor.fit_summary()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access certain results from this summary. For example, training and validation accuracies below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-127d02d5c824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train acc: %.3f, val acc: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_result' is not defined"
     ]
    }
   ],
   "source": [
    "print('Train acc: %.3f, val acc: %.3f' %(fit_result['train_acc'], fit_result['valid_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model and optimum hyperparameters: Learning rate, batch size, epochs can be printed with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result['fit_history']['best_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the predict function to run on different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_dataset.iloc[0]['image']\n",
    "predictor.predict(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictor.predict(test_dataset)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
